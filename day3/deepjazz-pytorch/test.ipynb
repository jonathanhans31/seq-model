{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# data preprocessing import\n",
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords, abstract_grammars = get_musical_data('data/original_metheny.mid')\n",
    "corpus, tones, tones_indices, indices_tones = get_corpus_data(abstract_grammars)\n",
    "N_tones = len(set(corpus))\n",
    "x_initializer = np.zeros((1, 1, 78))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_id = \"GAN_120\"\n",
    "net = Model(78,128,78)\n",
    "net.load_state_dict(torch.load(\"./models/{}_deepjazz.pth\".format(experiment_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tones(net, sequence_length = 50):\n",
    "    tones = []\n",
    "    seed = torch.zeros([1,1,78])\n",
    "    net.hidden = net.init_hidden()\n",
    "    for seq in range(sequence_length):\n",
    "        seed,_ = net(seed)\n",
    "        out = seed.argmax(-1)\n",
    "        tones.append(out.data.numpy()[0])\n",
    "#         print(output.size())\n",
    "    return tones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 51 sounds using the predicted values for the set of chords (\"1\") and after pruning\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"2\") and after pruning\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"3\") and after pruning\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"4\") and after pruning\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"5\") and after pruning\n",
      "Your generated music is saved in output/GAN_120music_gan.midi\n",
      "Out Stream\n",
      "{0.0} <music21.tempo.MetronomeMark Quarter=100>\n",
      "{0.0} <music21.chord.Chord E-4 G4 C4 B-3 G#2>\n",
      "{0.5} <music21.note.Note G#>\n",
      "{0.75} <music21.note.Note G>\n",
      "{1.25} <music21.note.Note E->\n",
      "{1.75} <music21.note.Note B->\n",
      "{2.0} <music21.note.Note E->\n",
      "{2.0} <music21.chord.Chord B-3 F4 D4 A3>\n",
      "{2.25} <music21.note.Note B->\n",
      "{2.75} <music21.note.Note G>\n",
      "{3.25} <music21.note.Note B->\n",
      "{3.75} <music21.note.Note D>\n",
      "{4.0} <music21.chord.Chord E-4 G3 G#3 C4>\n",
      "{4.25} <music21.note.Note F>\n",
      "{4.5} <music21.note.Note A>\n",
      "{4.75} <music21.note.Note B->\n",
      "{5.25} <music21.note.Note D>\n",
      "{5.75} <music21.note.Note F>\n",
      "{6.0} <music21.note.Note B->\n",
      "{6.0} <music21.chord.Chord F4 B-3 D4 G3>\n",
      "{6.5} <music21.note.Note D>\n",
      "{7.0} <music21.note.Note F>\n",
      "{7.5} <music21.note.Note B->\n",
      "{8.0} <music21.note.Note D>\n",
      "{8.0} <music21.chord.Chord E-4 G#3 C4 F3>\n",
      "{8.5} <music21.note.Note F>\n",
      "{9.0} <music21.note.Note B->\n",
      "{9.5} <music21.note.Note D>\n",
      "{10.0} <music21.note.Note F>\n",
      "{10.0} <music21.chord.Chord F4 D4 B-3 G3>\n",
      "{10.25} <music21.note.Note A>\n",
      "{10.75} <music21.note.Note D>\n",
      "{11.0} <music21.note.Note F>\n",
      "{11.5} <music21.note.Note B->\n",
      "{12.0} <music21.note.Note D>\n",
      "{12.0} <music21.chord.Chord G#3 C#4 F3>\n",
      "{12.0} <music21.chord.Chord E-4 C#4 C4>\n",
      "{12.5} <music21.note.Note F>\n",
      "{12.75} <music21.note.Note A>\n",
      "{13.25} <music21.note.Note B->\n",
      "{13.5} <music21.note.Note D>\n",
      "{14.0} <music21.note.Note F>\n",
      "{14.0} <music21.chord.Chord B-3 E-3 C4 G3 G#1>\n",
      "{14.25} <music21.note.Note B->\n",
      "{14.75} <music21.note.Note D>\n",
      "{15.25} <music21.note.Note F>\n",
      "{15.5} <music21.note.Note A>\n",
      "{15.75} <music21.note.Note B->\n",
      "{16.0} <music21.note.Note D>\n",
      "{16.0} <music21.chord.Chord C4 A3 E4 G3 F2>\n",
      "{16.25} <music21.note.Note F>\n",
      "{16.5} <music21.note.Note B->\n",
      "{17.0} <music21.note.Note D>\n",
      "{17.25} <music21.note.Note F>\n",
      "{17.5} <music21.note.Note A>\n",
      "{17.75} <music21.chord.Chord E4 C4 A3 G3 F2>\n",
      "{18.0} <music21.note.Note D>\n",
      "{18.25} <music21.note.Note F>\n",
      "{18.5} <music21.note.Note B->\n",
      "{18.5} <music21.chord.Chord F3 B-3 A3 D4>\n",
      "{19.0} <music21.note.Note D>\n",
      "{19.5} <music21.note.Note F>\n",
      "{20.0} <music21.note.Note B->\n",
      "{20.25} <music21.note.Note D>\n"
     ]
    }
   ],
   "source": [
    "def generate_music(experiment_id, corpus = corpus, abstract_grammars = abstract_grammars, \n",
    "                   tones = tones, tones_indices = tones_indices, indices_tones = indices_tones, \n",
    "                   T_y = 10, max_tries = 1000, diversity = 0.5):\n",
    "    \"\"\"\n",
    "    Generates music using a model trained to learn musical patterns of a jazz soloist. Creates an audio stream\n",
    "    to save the music and play it.\n",
    "    \n",
    "    Arguments:\n",
    "    model -- Keras model Instance, output of djmodel()\n",
    "    corpus -- musical corpus, list of 193 tones as strings (ex: 'C,0.333,<P1,d-5>')\n",
    "    abstract_grammars -- list of grammars, on element can be: 'S,0.250,<m2,P-4> C,0.250,<P4,m-2> A,0.250,<P4,m-2>'\n",
    "    tones -- set of unique tones, ex: 'A,0.250,<M2,d-4>' is one element of the set.\n",
    "    tones_indices -- a python dictionary mapping unique tone (ex: A,0.250,< m2,P-4 >) into their corresponding indices (0-77)\n",
    "    indices_tones -- a python dictionary mapping indices (0-77) into their corresponding unique tone (ex: A,0.250,< m2,P-4 >)\n",
    "    Tx -- integer, number of time-steps used at training time\n",
    "    temperature -- scalar value, defines how conservative/creative the model is when generating music\n",
    "    \n",
    "    Returns:\n",
    "    predicted_tones -- python list containing predicted tones\n",
    "    \"\"\"\n",
    "    out_stream = stream.Stream()\n",
    "    curr_offset = 0.0\n",
    "    num_chords = int(len(chords)/3) # Number of different set of chords\n",
    "    \n",
    "    for i in range(1, num_chords):\n",
    "        curr_chords = stream.Voice()\n",
    "        \n",
    "        # Loop over the chords of the current set of chords\n",
    "        for j in chords[i]:\n",
    "            # Add chord to the current chods wit hthe adequate offset, no need to understand this\n",
    "            curr_chords.insert((j.offset % 4), j)\n",
    "        \n",
    "        # Generate sequence of tones using the model\n",
    "        indices = generate_tones(net)\n",
    "        pred = [indices_tones[p] for p in indices]\n",
    "        \n",
    "        predicted_tones = 'C,0.25 '\n",
    "        for k in range(len(pred) - 1):\n",
    "            predicted_tones += pred[k] + ' ' \n",
    "        \n",
    "        predicted_tones +=  pred[-1]\n",
    "                \n",
    "        #### POST PROCESSING OF THE PREDICTED TONES ####\n",
    "        # We will consider \"A\" and \"X\" as \"C\" tones. It is a common choice.\n",
    "        predicted_tones = predicted_tones.replace(' A',' C').replace(' X',' C')\n",
    "\n",
    "        # Pruning #1: smoothing measure\n",
    "        predicted_tones = prune_grammar(predicted_tones)\n",
    "        \n",
    "        # Use predicted tones and current chords to generate sounds\n",
    "        sounds = unparse_grammar(predicted_tones, curr_chords)\n",
    "\n",
    "        # Pruning #2: removing repeated and too close together sounds\n",
    "        sounds = prune_notes(sounds)\n",
    "\n",
    "        # Quality assurance: clean up sounds\n",
    "        sounds = clean_up_notes(sounds)\n",
    "\n",
    "        # Print number of tones/notes in sounds\n",
    "        print('Generated %s sounds using the predicted values for the set of chords (\"%s\") and after pruning' % (len([k for k in sounds if isinstance(k, note.Note)]), i))\n",
    "        \n",
    "        # Insert sounds into the output stream\n",
    "        if i == 1:\n",
    "            for m in sounds:\n",
    "                out_stream.insert(curr_offset + m.offset, m)\n",
    "        for mc in curr_chords:\n",
    "            out_stream.insert(curr_offset + mc.offset, mc)\n",
    "\n",
    "        curr_offset += 4.0\n",
    "        \n",
    "        \n",
    "    # Initialize tempo of the output stream with 130 bit per minute\n",
    "    out_stream.insert(0.0, tempo.MetronomeMark(number=100))\n",
    "\n",
    "    # Save audio stream to fine\n",
    "    mf = midi.translate.streamToMidiFile(out_stream)\n",
    "    mf.open(\"output/\"+experiment_id+\"_music_gan.midi\", 'wb')\n",
    "    mf.write()\n",
    "    print(\"Your generated music is saved in output/\"+experiment_id+\"music_gan.midi\")\n",
    "    mf.close()\n",
    "    print(\"Out Stream\")\n",
    "    out_stream.show(\"text\")\n",
    "generate_music(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
