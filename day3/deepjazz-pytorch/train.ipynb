{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# data preprocessing import\n",
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def mkdir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "mkdir(\"models/\")\n",
    "experiment_id = \"GAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (60, 100, 78)\n",
      "number of training examples: 60\n",
      "Tx (length of sequence): 100\n",
      "total # of unique values: 78\n",
      "Shape of Y: (100, 60, 78)\n"
     ]
    }
   ],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('shape of X:', X.shape)\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tx, n_sample, n_feature): (100, 60, 78)\n"
     ]
    }
   ],
   "source": [
    "# Convert X into (Tx, n_sample, n_feature)\n",
    "X = np.transpose(X,(1,0,2))\n",
    "print(\"(Tx, n_sample, n_feature):\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "n_sequence = X.shape[0]\n",
    "n_step = X.shape[1]\n",
    "n_input = n_output = X.shape[2]\n",
    "n_hidden = 128\n",
    "n_epoch = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFDiscriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Linear(in_features=7800, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup model, optimizer\n",
    "net = Model(n_input, n_hidden, n_output)\n",
    "disc = FFDiscriminator(n_sequence*n_output, n_hidden , 1) # Real of Fake\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "disc_optimizer = optim.Adam(disc.parameters(), lr=0.01)\n",
    "\n",
    "net.cuda()\n",
    "disc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test model inference\")\n",
    "\n",
    "# dummy_x = torch.randn([n_sequence,1,n_input]).cuda()\n",
    "# print(\"Input Size:\",dummy_x.size())\n",
    "\n",
    "# dummy_pred,_ = net(dummy_x)\n",
    "# print(\"Output size:\", dummy_pred.size())\n",
    "\n",
    "# dummy_label = (torch.randn(dummy_pred.size())>0.5).argmax(dim=1)\n",
    "# print(\"Label size:\",dummy_label)\n",
    "\n",
    "# dummy_loss = F.cross_entropy(dummy_pred, dummy_label)\n",
    "# print(\"Loss\", dummy_loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 0, Loss 715.5747337341309\n",
      "Saving the model to models/GAN_0_deepjazz.pth\n",
      "Epoch 1, Loss 1785.5273280143738\n",
      "Saving the model to models/GAN_1_deepjazz.pth\n",
      "Epoch 2, Loss 2393.1868720054626\n",
      "Saving the model to models/GAN_2_deepjazz.pth\n",
      "Epoch 3, Loss 1603.4001197814941\n",
      "Saving the model to models/GAN_3_deepjazz.pth\n",
      "Epoch 4, Loss 684.1167373657227\n",
      "Saving the model to models/GAN_4_deepjazz.pth\n",
      "Epoch 5, Loss 576.2429103851318\n",
      "Saving the model to models/GAN_5_deepjazz.pth\n",
      "Epoch 6, Loss 562.674334526062\n",
      "Saving the model to models/GAN_6_deepjazz.pth\n",
      "Epoch 7, Loss 604.6301383972168\n",
      "Saving the model to models/GAN_7_deepjazz.pth\n",
      "Epoch 8, Loss 599.9206228256226\n",
      "Saving the model to models/GAN_8_deepjazz.pth\n",
      "Epoch 9, Loss 565.1851501464844\n",
      "Saving the model to models/GAN_9_deepjazz.pth\n",
      "Epoch 10, Loss 610.5361547470093\n",
      "Saving the model to models/GAN_10_deepjazz.pth\n",
      "Epoch 11, Loss 600.2499160766602\n",
      "Saving the model to models/GAN_11_deepjazz.pth\n",
      "Epoch 12, Loss 601.536506652832\n",
      "Saving the model to models/GAN_12_deepjazz.pth\n",
      "Epoch 13, Loss 602.0386447906494\n",
      "Saving the model to models/GAN_13_deepjazz.pth\n",
      "Epoch 14, Loss 601.4442529678345\n",
      "Saving the model to models/GAN_14_deepjazz.pth\n",
      "Epoch 15, Loss 628.0796804428101\n",
      "Saving the model to models/GAN_15_deepjazz.pth\n",
      "Epoch 16, Loss 623.4698715209961\n",
      "Saving the model to models/GAN_16_deepjazz.pth\n",
      "Epoch 17, Loss 622.0658445358276\n",
      "Saving the model to models/GAN_17_deepjazz.pth\n",
      "Epoch 18, Loss 652.2962961196899\n",
      "Saving the model to models/GAN_18_deepjazz.pth\n",
      "Epoch 19, Loss 642.0220260620117\n",
      "Saving the model to models/GAN_19_deepjazz.pth\n",
      "Epoch 20, Loss 642.9547338485718\n",
      "Saving the model to models/GAN_20_deepjazz.pth\n",
      "Epoch 21, Loss 657.4198131561279\n",
      "Saving the model to models/GAN_21_deepjazz.pth\n",
      "Epoch 22, Loss 650.2783441543579\n",
      "Saving the model to models/GAN_22_deepjazz.pth\n",
      "Epoch 23, Loss 646.8237285614014\n",
      "Saving the model to models/GAN_23_deepjazz.pth\n",
      "Epoch 24, Loss 665.7201519012451\n",
      "Saving the model to models/GAN_24_deepjazz.pth\n",
      "Epoch 25, Loss 650.2892513275146\n",
      "Saving the model to models/GAN_25_deepjazz.pth\n",
      "Epoch 26, Loss 664.6706237792969\n",
      "Saving the model to models/GAN_26_deepjazz.pth\n",
      "Epoch 27, Loss 717.8415098190308\n",
      "Saving the model to models/GAN_27_deepjazz.pth\n",
      "Epoch 28, Loss 689.9922885894775\n",
      "Saving the model to models/GAN_28_deepjazz.pth\n",
      "Epoch 29, Loss 654.261064529419\n",
      "Saving the model to models/GAN_29_deepjazz.pth\n",
      "Epoch 30, Loss 718.8159017562866\n",
      "Saving the model to models/GAN_30_deepjazz.pth\n",
      "Epoch 31, Loss 726.514048576355\n",
      "Saving the model to models/GAN_31_deepjazz.pth\n",
      "Epoch 32, Loss 729.3363151550293\n",
      "Saving the model to models/GAN_32_deepjazz.pth\n",
      "Epoch 33, Loss 723.375186920166\n",
      "Saving the model to models/GAN_33_deepjazz.pth\n",
      "Epoch 34, Loss 745.0532674789429\n",
      "Saving the model to models/GAN_34_deepjazz.pth\n",
      "Epoch 35, Loss 730.4118204116821\n",
      "Saving the model to models/GAN_35_deepjazz.pth\n",
      "Epoch 36, Loss 700.7439241409302\n",
      "Saving the model to models/GAN_36_deepjazz.pth\n",
      "Epoch 37, Loss 725.1577711105347\n",
      "Saving the model to models/GAN_37_deepjazz.pth\n",
      "Epoch 38, Loss 748.1827964782715\n",
      "Saving the model to models/GAN_38_deepjazz.pth\n",
      "Epoch 39, Loss 736.5676498413086\n",
      "Saving the model to models/GAN_39_deepjazz.pth\n",
      "Epoch 40, Loss 747.7502107620239\n",
      "Saving the model to models/GAN_40_deepjazz.pth\n",
      "Epoch 41, Loss 776.9734163284302\n",
      "Saving the model to models/GAN_41_deepjazz.pth\n",
      "Epoch 42, Loss 793.7750453948975\n",
      "Saving the model to models/GAN_42_deepjazz.pth\n",
      "Epoch 43, Loss 791.28883934021\n",
      "Saving the model to models/GAN_43_deepjazz.pth\n",
      "Epoch 44, Loss 780.3044185638428\n",
      "Saving the model to models/GAN_44_deepjazz.pth\n",
      "Epoch 45, Loss 758.2569303512573\n",
      "Saving the model to models/GAN_45_deepjazz.pth\n",
      "Epoch 46, Loss 735.3864250183105\n",
      "Saving the model to models/GAN_46_deepjazz.pth\n",
      "Epoch 47, Loss 1696.419023513794\n",
      "Saving the model to models/GAN_47_deepjazz.pth\n",
      "Epoch 48, Loss 8967.185592651367\n",
      "Saving the model to models/GAN_48_deepjazz.pth\n",
      "Epoch 49, Loss 32429.502227783203\n",
      "Saving the model to models/GAN_49_deepjazz.pth\n",
      "Epoch 50, Loss 42611.98830986023\n",
      "Saving the model to models/GAN_50_deepjazz.pth\n",
      "Epoch 51, Loss 53345.61993217468\n",
      "Saving the model to models/GAN_51_deepjazz.pth\n",
      "Epoch 52, Loss 37272.769929885864\n",
      "Saving the model to models/GAN_52_deepjazz.pth\n",
      "Epoch 53, Loss 27963.25824737549\n",
      "Saving the model to models/GAN_53_deepjazz.pth\n",
      "Epoch 54, Loss 10170.814558029175\n",
      "Saving the model to models/GAN_54_deepjazz.pth\n",
      "Epoch 55, Loss 1039.1604108810425\n",
      "Saving the model to models/GAN_55_deepjazz.pth\n",
      "Epoch 56, Loss 2396.2874870300293\n",
      "Saving the model to models/GAN_56_deepjazz.pth\n",
      "Epoch 57, Loss 2628.022455215454\n",
      "Saving the model to models/GAN_57_deepjazz.pth\n",
      "Epoch 58, Loss 2864.17835521698\n",
      "Saving the model to models/GAN_58_deepjazz.pth\n",
      "Epoch 59, Loss 4140.115816116333\n",
      "Saving the model to models/GAN_59_deepjazz.pth\n",
      "Epoch 60, Loss 3123.6550483703613\n",
      "Saving the model to models/GAN_60_deepjazz.pth\n",
      "Epoch 61, Loss 4874.88142490387\n",
      "Saving the model to models/GAN_61_deepjazz.pth\n",
      "Epoch 62, Loss 2883.7358388900757\n",
      "Saving the model to models/GAN_62_deepjazz.pth\n",
      "Epoch 63, Loss 906.319128036499\n",
      "Saving the model to models/GAN_63_deepjazz.pth\n",
      "Epoch 64, Loss 1356.0085334777832\n",
      "Saving the model to models/GAN_64_deepjazz.pth\n",
      "Epoch 65, Loss 1102.689290046692\n",
      "Saving the model to models/GAN_65_deepjazz.pth\n",
      "Epoch 66, Loss 771.9730854034424\n",
      "Saving the model to models/GAN_66_deepjazz.pth\n",
      "Epoch 67, Loss 875.7573823928833\n",
      "Saving the model to models/GAN_67_deepjazz.pth\n",
      "Epoch 68, Loss 1008.5733442306519\n",
      "Saving the model to models/GAN_68_deepjazz.pth\n",
      "Epoch 69, Loss 755.2663769721985\n",
      "Saving the model to models/GAN_69_deepjazz.pth\n",
      "Epoch 70, Loss 842.1425762176514\n",
      "Saving the model to models/GAN_70_deepjazz.pth\n",
      "Epoch 71, Loss 786.0908584594727\n",
      "Saving the model to models/GAN_71_deepjazz.pth\n",
      "Epoch 72, Loss 774.076367855072\n",
      "Saving the model to models/GAN_72_deepjazz.pth\n",
      "Epoch 73, Loss 902.2472853660583\n",
      "Saving the model to models/GAN_73_deepjazz.pth\n",
      "Epoch 74, Loss 713.5677824020386\n",
      "Saving the model to models/GAN_74_deepjazz.pth\n",
      "Epoch 75, Loss 843.1502885818481\n",
      "Saving the model to models/GAN_75_deepjazz.pth\n",
      "Epoch 76, Loss 815.6307497024536\n",
      "Saving the model to models/GAN_76_deepjazz.pth\n",
      "Epoch 77, Loss 935.2248754501343\n",
      "Saving the model to models/GAN_77_deepjazz.pth\n",
      "Epoch 78, Loss 889.8327884674072\n",
      "Saving the model to models/GAN_78_deepjazz.pth\n",
      "Epoch 79, Loss 880.7720785140991\n",
      "Saving the model to models/GAN_79_deepjazz.pth\n",
      "Epoch 80, Loss 917.9106059074402\n",
      "Saving the model to models/GAN_80_deepjazz.pth\n",
      "Epoch 81, Loss 803.4923486709595\n",
      "Saving the model to models/GAN_81_deepjazz.pth\n",
      "Epoch 82, Loss 912.6623659133911\n",
      "Saving the model to models/GAN_82_deepjazz.pth\n",
      "Epoch 83, Loss 787.9567756652832\n",
      "Saving the model to models/GAN_83_deepjazz.pth\n",
      "Epoch 84, Loss 769.7314577102661\n",
      "Saving the model to models/GAN_84_deepjazz.pth\n",
      "Epoch 85, Loss 848.7409715652466\n",
      "Saving the model to models/GAN_85_deepjazz.pth\n",
      "Epoch 86, Loss 817.9720649719238\n",
      "Saving the model to models/GAN_86_deepjazz.pth\n",
      "Epoch 87, Loss 1031.462378025055\n",
      "Saving the model to models/GAN_87_deepjazz.pth\n",
      "Epoch 88, Loss 712.7576532363892\n",
      "Saving the model to models/GAN_88_deepjazz.pth\n",
      "Epoch 89, Loss 854.759316444397\n",
      "Saving the model to models/GAN_89_deepjazz.pth\n",
      "Epoch 90, Loss 814.8050727844238\n",
      "Saving the model to models/GAN_90_deepjazz.pth\n",
      "Epoch 91, Loss 894.631031036377\n",
      "Saving the model to models/GAN_91_deepjazz.pth\n",
      "Epoch 92, Loss 934.7593202590942\n",
      "Saving the model to models/GAN_92_deepjazz.pth\n",
      "Epoch 93, Loss 829.6140098571777\n",
      "Saving the model to models/GAN_93_deepjazz.pth\n",
      "Epoch 94, Loss 767.1971082687378\n",
      "Saving the model to models/GAN_94_deepjazz.pth\n",
      "Epoch 95, Loss 767.6013717651367\n",
      "Saving the model to models/GAN_95_deepjazz.pth\n",
      "Epoch 96, Loss 757.4942598342896\n",
      "Saving the model to models/GAN_96_deepjazz.pth\n",
      "Epoch 97, Loss 740.2316780090332\n",
      "Saving the model to models/GAN_97_deepjazz.pth\n",
      "Epoch 98, Loss 769.7671527862549\n",
      "Saving the model to models/GAN_98_deepjazz.pth\n",
      "Epoch 99, Loss 828.7096395492554\n",
      "Saving the model to models/GAN_99_deepjazz.pth\n",
      "Epoch 100, Loss 868.9976024627686\n",
      "Saving the model to models/GAN_100_deepjazz.pth\n",
      "Epoch 101, Loss 766.8583889007568\n",
      "Saving the model to models/GAN_101_deepjazz.pth\n",
      "Epoch 102, Loss 811.9235401153564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model to models/GAN_102_deepjazz.pth\n",
      "Epoch 103, Loss 845.5573635101318\n",
      "Saving the model to models/GAN_103_deepjazz.pth\n",
      "Epoch 104, Loss 831.5645980834961\n",
      "Saving the model to models/GAN_104_deepjazz.pth\n",
      "Epoch 105, Loss 832.6157693862915\n",
      "Saving the model to models/GAN_105_deepjazz.pth\n",
      "Epoch 106, Loss 894.4226312637329\n",
      "Saving the model to models/GAN_106_deepjazz.pth\n",
      "Epoch 107, Loss 761.6975440979004\n",
      "Saving the model to models/GAN_107_deepjazz.pth\n",
      "Epoch 108, Loss 809.2255754470825\n",
      "Saving the model to models/GAN_108_deepjazz.pth\n",
      "Epoch 109, Loss 809.7551517486572\n",
      "Saving the model to models/GAN_109_deepjazz.pth\n",
      "Epoch 110, Loss 895.6041879653931\n",
      "Saving the model to models/GAN_110_deepjazz.pth\n",
      "Epoch 111, Loss 818.7526054382324\n",
      "Saving the model to models/GAN_111_deepjazz.pth\n",
      "Epoch 112, Loss 812.4434118270874\n",
      "Saving the model to models/GAN_112_deepjazz.pth\n",
      "Epoch 113, Loss 839.8631315231323\n",
      "Saving the model to models/GAN_113_deepjazz.pth\n",
      "Epoch 114, Loss 1015.0926151275635\n",
      "Saving the model to models/GAN_114_deepjazz.pth\n",
      "Epoch 115, Loss 822.4765300750732\n",
      "Saving the model to models/GAN_115_deepjazz.pth\n",
      "Epoch 116, Loss 1238.8577737808228\n",
      "Saving the model to models/GAN_116_deepjazz.pth\n",
      "Epoch 117, Loss 2109.6111917495728\n",
      "Saving the model to models/GAN_117_deepjazz.pth\n",
      "Epoch 118, Loss 1469.8373851776123\n",
      "Saving the model to models/GAN_118_deepjazz.pth\n",
      "Epoch 119, Loss 2272.425281524658\n",
      "Saving the model to models/GAN_119_deepjazz.pth\n",
      "Epoch 120, Loss 880.4773254394531\n",
      "Saving the model to models/GAN_120_deepjazz.pth\n",
      "Epoch 121, Loss 951.7003746032715\n",
      "Saving the model to models/GAN_121_deepjazz.pth\n",
      "Epoch 122, Loss 1022.8656673431396\n",
      "Saving the model to models/GAN_122_deepjazz.pth\n",
      "Epoch 123, Loss 1061.1788864135742\n",
      "Saving the model to models/GAN_123_deepjazz.pth\n",
      "Epoch 124, Loss 1104.4953527450562\n",
      "Saving the model to models/GAN_124_deepjazz.pth\n",
      "Epoch 125, Loss 1113.9088163375854\n",
      "Saving the model to models/GAN_125_deepjazz.pth\n",
      "Epoch 126, Loss 1112.686598777771\n",
      "Saving the model to models/GAN_126_deepjazz.pth\n",
      "Epoch 127, Loss 1101.173336982727\n",
      "Saving the model to models/GAN_127_deepjazz.pth\n",
      "Epoch 128, Loss 1065.6776809692383\n",
      "Saving the model to models/GAN_128_deepjazz.pth\n",
      "Epoch 129, Loss 1052.6276607513428\n",
      "Saving the model to models/GAN_129_deepjazz.pth\n",
      "Epoch 130, Loss 1053.8834056854248\n",
      "Saving the model to models/GAN_130_deepjazz.pth\n",
      "Epoch 131, Loss 1091.0793266296387\n",
      "Saving the model to models/GAN_131_deepjazz.pth\n",
      "Epoch 132, Loss 4880.829495429993\n",
      "Saving the model to models/GAN_132_deepjazz.pth\n",
      "Epoch 133, Loss 5068.177374839783\n",
      "Saving the model to models/GAN_133_deepjazz.pth\n",
      "Epoch 134, Loss 4322.872354507446\n",
      "Saving the model to models/GAN_134_deepjazz.pth\n",
      "Epoch 135, Loss 1245.0810565948486\n",
      "Saving the model to models/GAN_135_deepjazz.pth\n",
      "Epoch 136, Loss 1201.0199012756348\n",
      "Saving the model to models/GAN_136_deepjazz.pth\n",
      "Epoch 137, Loss 1073.2615385055542\n",
      "Saving the model to models/GAN_137_deepjazz.pth\n",
      "Epoch 138, Loss 1122.4322681427002\n",
      "Saving the model to models/GAN_138_deepjazz.pth\n",
      "Epoch 139, Loss 1153.9765539169312\n",
      "Saving the model to models/GAN_139_deepjazz.pth\n",
      "Epoch 140, Loss 1295.4151458740234\n",
      "Saving the model to models/GAN_140_deepjazz.pth\n",
      "Epoch 141, Loss 1561.5197820663452\n",
      "Saving the model to models/GAN_141_deepjazz.pth\n",
      "Epoch 142, Loss 2574.9058837890625\n",
      "Saving the model to models/GAN_142_deepjazz.pth\n",
      "Epoch 143, Loss 1133.3985118865967\n",
      "Saving the model to models/GAN_143_deepjazz.pth\n",
      "Epoch 144, Loss 5124.536806106567\n",
      "Saving the model to models/GAN_144_deepjazz.pth\n",
      "Epoch 145, Loss 1990.1188373565674\n",
      "Saving the model to models/GAN_145_deepjazz.pth\n",
      "Epoch 146, Loss 2672.6062631607056\n",
      "Saving the model to models/GAN_146_deepjazz.pth\n",
      "Epoch 147, Loss 6837.740295410156\n",
      "Saving the model to models/GAN_147_deepjazz.pth\n",
      "Epoch 148, Loss 7723.587652206421\n",
      "Saving the model to models/GAN_148_deepjazz.pth\n",
      "Epoch 149, Loss 21858.796255111694\n",
      "Saving the model to models/GAN_149_deepjazz.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "X = X.astype(\"float32\")\n",
    "Y = Y.astype(int)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(n_epoch):\n",
    "    total_loss = 0\n",
    "    for step in range(n_step):\n",
    "        x = torch.tensor(X[:,step,:]).unsqueeze(1)  # (30,1,78)\n",
    "        y = torch.tensor(Y[:,step,:], dtype=torch.long).argmax(dim=1) # (30,1)\n",
    "        y_seq = torch.tensor(Y[:,step,:],dtype=torch.float) # (30,1,78)\n",
    "        \n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y_seq = y_seq.cuda()\n",
    "        # Initialize hidden state\n",
    "        net.hidden = net.init_hidden(use_cuda=True)\n",
    "\n",
    "        # Feed the data\n",
    "        prob_y, _ = net(x)                             # (30,78)\n",
    "        \n",
    "        # Discriminator's Step\n",
    "        # ===========================================================================================\n",
    "        # Feed the prob_y to the FFDiscriminator\n",
    "        fake_prob = disc(prob_y.view(-1).cuda())\n",
    "        loss_gan_fake = F.binary_cross_entropy_with_logits(fake_prob, torch.zeros_like(fake_prob).cuda())\n",
    "        \n",
    "        real_prob = disc(y_seq.view(-1).cuda())\n",
    "        loss_gan_real = F.binary_cross_entropy_with_logits(real_prob, torch.ones_like(real_prob).cuda())\n",
    "        disc_loss = loss_gan_real + loss_gan_fake\n",
    "        \n",
    "        disc_optimizer.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        disc_optimizer.step()\n",
    "        \n",
    "        # Generator's Step\n",
    "        # ===========================================================================================\n",
    "        net.hidden = net.init_hidden(use_cuda=True)\n",
    "        prob_y, _ = net(x)\n",
    "        fake_prob = disc(prob_y.view(-1).cuda())\n",
    "        gan_loss = F.binary_cross_entropy_with_logits(fake_prob, torch.ones_like(fake_prob).cuda())\n",
    "        chord_loss = F.cross_entropy(prob_y, y)\n",
    "        \n",
    "        loss = chord_loss + gan_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.cpu().data.numpy()\n",
    "#         print(list(y.data.numpy().squeeze()))\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    print(\"Epoch {}, Loss {}\".format(epoch, total_loss))\n",
    "    save_path = \"models/{}_{}_deepjazz.pth\".format(experiment_id, epoch)\n",
    "    print(\"Saving the model to\", save_path)\n",
    "    torch.save(net.state_dict(), save_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUnHWd7/H3t5au3tNZOgtZSIQIAipLxHgZVxwI6BXujMzBq0POXM5hjhfOdUbnjHCdGUYdr8vMqMMM4uEoCjPOIOOoBEURWcQNJeyEGNJAkg4JSSfdSa+1f+8fz1OdSnqr7iT1VLo+r3P6VNWvnqr69dNd9anf8vwec3dERETKxaKugIiI1B6Fg4iIjKFwEBGRMRQOIiIyhsJBRETGUDiIiMgYCgcRERlD4SAiImMoHEREZIxE1BWYqQULFvjKlSujroaIyAnj8ccf3+funZVse8KGw8qVK9m4cWPU1RAROWGY2fZKt1W3koiIjKFwEBGRMRQOIiIyhsJBRETGUDiIiMgYCgcRERlD4SAiImMoHKSmPLmjj+deORh1NUTqnsJBasrf3vM8X7hvS9TVEKl7J+wR0jI7DYzkSMYs6mqI1D21HKSmDGbypPOFqKshUvcUDlJTBjN5Mrli1NUQqXsKB6kZhaIznC2o5SBSAxQOUjOGsnkA0mo5iERO4SA1YygThEMmp5aDSNQUDlIzSuGQzqvlIBI1hYPUjIF0EA7ZfJFi0SOujUh9qygczGybmT1rZk+Z2cawbJ6Z3W9mW8PLuWG5mdlNZtZlZs+Y2bllz7M+3H6rma0vKz8vfP6u8LGa6F6HhjKHupOyBbUeRKI0nZbDO939bHdfE96+HnjA3VcDD4S3AS4BVoc/1wC3QBAmwI3Am4HzgRtLgRJuc03Z49bN+DeSE9Zg2K0EkNa4g0ikjqZb6TLg9vD67cDlZeV3eOBRoMPMlgAXA/e7e6+79wH3A+vC+9rd/dfu7sAdZc8ldeTwcFDLQSRKlYaDAz8xs8fN7JqwbJG77wYILxeG5UuB7rLH7gzLJivfOU651JmhsnDI6FgHkUhVurbSBe6+y8wWAveb2e8m2Xa88QKfQfnYJw6C6RqAFStWTF5jOeGo5SBSOypqObj7rvByL/A9gjGDPWGXEOHl3nDzncDysocvA3ZNUb5snPLx6nGru69x9zWdnZ2VVF1OIBpzEKkdU4aDmbWYWVvpOnAR8BywASjNOFoP3B1e3wBcFc5aWgscDLud7gMuMrO54UD0RcB94X0DZrY2nKV0VdlzSR05vFtJLQeRKFXSrbQI+F44uzQB/Lu7/9jMHgPuMrOrgR3AFeH29wKXAl3AMPAnAO7ea2afBh4Lt/uUu/eG1z8MfBNoAn4U/kidUctBpHZMGQ7u/hLwxnHK9wMXjlPuwLUTPNdtwG3jlG8EzqqgvjKLDaYVDiK1QkdIS80YyuaZ05QE1K0kEjWFg9SMwUyB+a0NgFoOIlFTOEjNGEznWNCSArT4nkjUFA5SM4bKWg5atlskWgoHqRmDmfyhcFDLQSRSCgepCe7OUDbP3OYGzDTmIBI1hYPUhOFsAXdoTSVIJWJqOYhETOEgNaF0AFxLKkFjMq6Wg0jEFA5SE0rh0NaYoDGhcBCJmsJBakJpXaWWhgSppLqVRKKmcJCaUFo6o1UtB5GaoHCQmlDqVmpNJWhMxnQ+B5GIKRykJgxlDw1Ip5JxnQlOJGIKB6kJo91K4VRWtRxEoqVwkJowmAlaCq2ayipSExQOUhOGMnliBo3JGI3JuGYriURM4SA1YTCTpzWVwMyCI6TVchCJlMJBakIpHCBoPWjJbpFoKRykJgxl8rSUwkHHOYhETuEgNWEwk6e1MQgHHSEtEj2Fg9SEw7qVEnEKRSdXUECIREXhIDVhKJOnpaE05hAHdE4HkSgpHKQmDKYPdSs1JoN/S3UtiURH4SA1obxbKZVQy0EkagoHiZy7M5jJ05IKQiEVthy0hIZIdBQOErl0rkjRoTWVBA6NOWjxPZHoKBwkcoeW6w5bDgm1HESipnCQyJWfPxrKWg4acxCJjMJBIjdUdqIfKO9WUstBJCoVh4OZxc3sSTP7QXh7lZn9xsy2mtm3zawhLE+Ft7vC+1eWPccNYfkWM7u4rHxdWNZlZtcfu19PTgSDR4TDoW4ltRxEojKdlsNHgM1ltz8PfMndVwN9wNVh+dVAn7ufCnwp3A4zOwO4EjgTWAd8JQycOHAzcAlwBvCBcFupE6UT/RzZrZTWgLRIZCoKBzNbBrwH+Fp424B3Ad8JN7kduDy8fll4m/D+C8PtLwPudPeMu78MdAHnhz9d7v6Su2eBO8NtpU6UThE65iA4DUiLRKbSlsOXgb8ESu/W+cABd8+Ht3cCS8PrS4FugPD+g+H2o+VHPGai8jHM7Boz22hmG3t6eiqsutS6sd1KOghOJGpThoOZvRfY6+6PlxePs6lPcd90y8cWut/q7mvcfU1nZ+cktZYTydhupXDMQQPSIpFJVLDNBcD7zOxSoBFoJ2hJdJhZImwdLAN2hdvvBJYDO80sAcwBesvKS8ofM1G51IGhTB4zaA7HGhoTpamsCgeRqEzZcnD3G9x9mbuvJBhQftDdPwg8BLw/3Gw9cHd4fUN4m/D+B93dw/Irw9lMq4DVwG+Bx4DV4eynhvA1NhyT305OCIOZAi0NCWKxoBEZixkN8ZgGpEUiVEnLYSIfB+40s78DngS+HpZ/HfhXM+siaDFcCeDum8zsLuB5IA9c6+4FADO7DrgPiAO3ufumo6iXnGAGM7nR8YaSVCKmMQeRCE0rHNz9YeDh8PpLBDONjtwmDVwxweM/A3xmnPJ7gXunUxeZPYYyhdFF90pSybgOghOJkI6QlsiVL9dd0phUy0EkSgoHiVz5+aNLUomYBqRFIqRwkMiVnyK0pDEZ15LdIhFSOEjkBtLjdSvFtWS3SIQUDhK5oezYbqXGZIwRjTmIREbhIJFy96Bb6YiWQ2sqMXrktIhUn8JBIpXJF8kVfEy3UltjkoF0LqJaiYjCQSJ15Il+StoaEwyo5SASGYWDRGooE4wrHNmt1NaYZDCbp1gcdw1GETnOFA4SqYFM0HXUesQR0u2NCdxhMKvWg0gUFA4SqVLLoTWVPKy8LZy9pK4lkWgoHCRSpTGHI9dWamsMwkKD0iLRUDhIpAYmGZAGtRxEoqJwkEiNzlZqHDsgDWo5iERF4SCROtStpJaDSC1ROEikSh/+Ry68VwqHfoWDSCQUDhKpoUye5oY48fAUoSXt6lYSiZTCQSI1lB27rhIE53NIxk3dSiIRUThIpMZbrhvAzLS+kkiEFA4SqaFxThFaovWVRKKjcJBIDWUKYw6AK1E4iERH4SCRGpis5ZBSt5JIVBQOEqnhCQakQS0HkSgpHCRS2XyRVGL8f8NgQFrhIBIFhYNEKlcokoxPFA4J+tWtJBIJhYNEKpufOBzaGxMMZnTCH5EoKBwkUrmC0zBJt5J7cKCciFSXwkEiFXQr2bj3afE9kehMGQ5m1mhmvzWzp81sk5l9MixfZWa/MbOtZvZtM2sIy1Ph7a7w/pVlz3VDWL7FzC4uK18XlnWZ2fXH/teUWlQsOvmiTzLmUFpfSeEgUm2VtBwywLvc/Y3A2cA6M1sLfB74kruvBvqAq8Ptrwb63P1U4EvhdpjZGcCVwJnAOuArZhY3szhwM3AJcAbwgXBbmeVyxSLApAPSgAalRSIwZTh4YDC8mQx/HHgX8J2w/Hbg8vD6ZeFtwvsvNDMLy+9094y7vwx0AeeHP13u/pK7Z4E7w21llssVgoHmqbuVFA4i1VbRmEP4Df8pYC9wP/AicMDdS+39ncDS8PpSoBsgvP8gML+8/IjHTFQus1wuP1XLQd1KIlGpKBzcveDuZwPLCL7pv268zcLL8b4G+gzKxzCza8xso5lt7OnpmbriUtNyhcnDoV0n/BGJzLRmK7n7AeBhYC3QYWaldQ+WAbvC6zuB5QDh/XOA3vLyIx4zUfl4r3+ru69x9zWdnZ3TqbrUoGwYDg1TthzUrSRSbZXMVuo0s47wehPwbmAz8BDw/nCz9cDd4fUN4W3C+x90dw/LrwxnM60CVgO/BR4DVoeznxoIBq03HItfTmrb6JhDYvwxh8ZkjERMJ/wRicL4K54dbglwezirKAbc5e4/MLPngTvN7O+AJ4Gvh9t/HfhXM+siaDFcCeDum8zsLuB5IA9c6+4FADO7DrgPiAO3ufumY/YbSs2aqlspOOFPQi0HkQhMGQ7u/gxwzjjlLxGMPxxZngaumOC5PgN8Zpzye4F7K6ivzCLZKQakQYvviURFR0hLZHJTjDmAlu0WiYrCQSKTL5aOc5gqHNStJFJtCgeJzKHjHMYfkAZoTSUZzBSqVSURCSkcJDKlqazJCVZlhWDGUjavcBCpNoWDRKY0lXWyMYeGRIxM2MIQkepROEhkpprKCpBKxBUOIhFQOEhkDoXDxGMOqUSMTE7dSiLVpnCQyFRynEMqqW4lkSgoHCQyo2MOkwxIl7qVghVYRKRaFA4SmcrGHGLhtgoHkWpSOEhkKh1zAMhoOqtIVSkcJDLZabQcNO4gUl0KB4lMLj/18hmpRBxQOIhUm8JBIpMrFInHjHhskm6lZNhy0HRWkapSOEhkcoUiiUmCAdStJBIVhYNEJlsoTrp0BhzqVsoqHESqSuEgkckVipMuugdqOYhEReEgkcnlfdJprHDoADlNZRWpLoWDRCZXKE46UwnKZivl1HIQqSaFg0SmojGHpLqVRKKgcJDIVNZyULeSSBQUDhKZXMFJJqaayqqD4ESioHCQyEyn5aCprCLVpXCQyFQUDkl1K4lEQeEgkckVfMoB6dL9mq0kAnc/9Qqf/dHmqryWwkEiE7QcJh9zSMRjxGOmMQcR4Fdd+7n7yV1VeS2Fg0Qmm5+6WwnC80irW0mEdL5AU0O8Kq+lcJDIVLJ8BpTCQS0HkZFsgcZkjYSDmS03s4fMbLOZbTKzj4Tl88zsfjPbGl7ODcvNzG4ysy4ze8bMzi17rvXh9lvNbH1Z+Xlm9mz4mJvMbPK+BpkVKhlzgGA6q2YricBIrkBTsjrf6St5lTzwMXd/HbAWuNbMzgCuBx5w99XAA+FtgEuA1eHPNcAtEIQJcCPwZuB84MZSoITbXFP2uHVH/6tJratkzAGCGUtqOYhAOldDLQd33+3uT4TXB4DNwFLgMuD2cLPbgcvD65cBd3jgUaDDzJYAFwP3u3uvu/cB9wPrwvva3f3X7u7AHWXPJbNYJVNZIZixpDEHkVLLoUbCoZyZrQTOAX4DLHL33RAECLAw3Gwp0F32sJ1h2WTlO8cpl1mu4gHpZExTWUUIxxxqbUDazFqB/wL+zN37J9t0nDKfQfl4dbjGzDaa2caenp6pqiw1Llfw0SW5J5NKxNWtJAKkc8XaajmYWZIgGL7l7t8Ni/eEXUKEl3vD8p3A8rKHLwN2TVG+bJzyMdz9Vndf4+5rOjs7K6m61LCKxxw0lVUEqLFupXDm0NeBze7+xbK7NgClGUfrgbvLyq8KZy2tBQ6G3U73AReZ2dxwIPoi4L7wvgEzWxu+1lVlzyWzVLHo5Is+jeMc1HIQGclW7ziHRAXbXAD8MfCsmT0Vlv1f4HPAXWZ2NbADuCK8717gUqALGAb+BMDde83s08Bj4Xafcvfe8PqHgW8CTcCPwh+ZxXLF4MO+snDQVFYRd2ekirOVpgwHd/8F448LAFw4zvYOXDvBc90G3DZO+UbgrKnqIrNHrhAMK2kqq0hlSu+Bxho6zkHkmMvlK285NMRjZHIac5D6lg7fAzUz5iByPOQK0+hWUstBhBGFg9SDbBgOlS6foXCQejeSDcOh1o5zEDmWRsccpjhNKGgqqwgcajnUzPIZIsfDtLqVEnFyBadYHPfYSJG6oDEHqQvZaQxIl04VWuqKEqlHI9ng/1/dSjKr5aY15qBThYpoQFrqQr5YOs6hgqmspXDQuIPUsUNjDjrOQWaxQ8c5VDIgHXxT0owlqWdpDUhLPSiNH1R6mlBQy0HqmwakpS6UprJOZ8whrTEHqWM6zkHqwvSOkA7eDJqtJPVsdMwhoXCQWexQOFR2EBxotpLUt5FcgVQiRiw29XvmWFA4SCSmc5yDZiuJQLqK53IAhYNEZHTMYVoD0mo5SP2q5lngQOEgEZnu8hmgcJD6NpIrVm0aKygcJCIzG3NQt5LUr5Fs9c4CBwoHiUh2mudzALUcpL5l8gWaqnR0NCgcJCK5fOXLZ5S6lXQeaalnIxqQlnqQKxSJGcQrmJanAWkRDUhLncgVihW1GuDQUdSayir1bCSnMQepA9lCsaKlMwBiMaMhrvNIS31LZ9VykDqQKxQrWnSvJJWI6QhpqWsjOY05SB3I5b2iaawlqaTOIy31Td1KUhemM+YAwYwldStJvSoWnbQOgpN6MJ0xBwi6lTSVVepV6YuRxhxk1ptuy6EhoW4lqV+HTvSjg+BklssVnGRiGmMOCc1WkvpVOpeDBqRl1pvRmINmK0mdGqny+aOhgnAws9vMbK+ZPVdWNs/M7jezreHl3LDczOwmM+sys2fM7Nyyx6wPt99qZuvLys8zs2fDx9xkZtU5k4VEatrhoNlKUsdGTxFaS+EAfBNYd0TZ9cAD7r4aeCC8DXAJsDr8uQa4BYIwAW4E3gycD9xYCpRwm2vKHnfka8kslCv4tAek1a0k9Spdi91K7v4I0HtE8WXA7eH124HLy8rv8MCjQIeZLQEuBu5391537wPuB9aF97W7+6/d3YE7yp5LZrGg5TCdMQdNZZX6VZPdShNY5O67AcLLhWH5UqC7bLudYdlk5TvHKZdZLpufXrdSU0Oc4Uz+ONZIpHbVarfSdIz3VdBnUD7+k5tdY2YbzWxjT0/PDKsotWC6y2e0NyYZSCscpD6dSC2HPWGXEOHl3rB8J7C8bLtlwK4pypeNUz4ud7/V3de4+5rOzs4ZVl1qwXTHHNoaEwxk8hSKE353EJm1anLMYQIbgNKMo/XA3WXlV4WzltYCB8Nup/uAi8xsbjgQfRFwX3jfgJmtDWcpXVX2XDKLTXfMoa0xAcCgupakDqVz1T9COjHVBmb2H8A7gAVmtpNg1tHngLvM7GpgB3BFuPm9wKVAFzAM/AmAu/ea2aeBx8LtPuXupUHuDxPMiGoCfhT+yCyXzhVomGa3EsBAOsecpuTxqpZITRo9CK6WwsHdPzDBXReOs60D107wPLcBt41TvhE4a6p6yOxRLDoHR3J0NDVU/Jj2puBftX8kD3On2FhklikNSKem8YXqaOkIaam6gXSeokNHc+UtgLayloNIvUnnCqQSMWIVnFb3WFE4SNX1DWcBmNtcecuhNOagGUtSj6p9oh9QOEgERsOhpfKWw+iYQ0YtB6k/w1U+RSgoHCQCR9Ny6B9Ry0HqS89Ahp9sepXTFrdV9XUVDlJ1fUPBt//phYPGHKQ+ffbezYzkCvzVe86o6usqHKTqZtJyaEjESCViGnOQuvKrF/fx3Sdf4U/fdgqnLmyt6msrHKTqDgzniNmhrqJKtTcl6VfLQerIN365jcXtjVz3rlOr/toKB6m6vuEsc5sbpj0tr60xQb9aDlJHtu8f4g3L5lR1TaUShYNUXd9wdlrHOJS0afE9qSPuTnfvCMvnNUfy+goHqbq+ody0xhtK2hsT9I+oW0nqw77BLCO5AisUDlIvgpbDTMIhqdlKUjd29A4DsHxeUySvr3CQqjswnGPeNA6AK2lrTKhbSerGzr4gHNRykLrg7qMD0tOlcJCo9AxkuOPX2/joXU+xdyB9zJ//k/ds4uaHug4r27E/CIdlcxUOUgdGcgUy+eKMu5VGcgVyhcrPJf3Ytl7e+oUH6RnITPv1RACe2NHHWz77AH9z9ya+9+QrfPTbT1M8xieduufpXdzz9OHnOevuG2ZhWyqSmUqgcJAq6xsuHR09s24lmN7ie3c91k137wgPb9k79cYi43hiex/5ovP9ay/g//2P1/OLrn189ZEXj9nzD2by7BvM8mLP4GFffHb0Dkc2UwkUDlJlfUPB0dEzaTlUsoRGvlAc7astFJ0HfheEwiNb90379UQAtu0foq0xwRuXzeHKNy3nPW9Ywj/+5AVe7Bk8Js9f6j7KFZyX9w2Nlnf3jkQ23gAKB6myA2HLYV7LDLqVwjPATbb43i0Pv8g7/v5hXtgzwOPb++gdyrKgNcUvtvYc864AqQ/b9w+zakELZoaZ8fGLT6dQdH77cu/UD67Ajt5DgfC7VwcAyOaL7D44wvK50cxUAoWDVNmhdZWOpltp/JZDNl/kjke3ky86X/jxFn6y6VUa4jH+7N2r6RvOsWlX/8wrLnXr5X1DrJzfMnp72dwmWhribAk/yI/W9rDlEDPY8mrwP7rrwAhFR91KUj9K4TCzbqVw2e4Jxhx+9NxuegYyvHX1An66eQ/f3tjNBafOZ91ZiwF4ZGvPDGst9SqTL7DrwAgrFxwKh1jMeO3iNjbvPjZfNrb3DtPRnOQ1na1seTXoquruKx3joHCQOlFarnsmy2e0TzHm8I1fbmPVgha++qHz6GxLMZDOc9GZi1nQmuLMk9p55AWFg0xPd+8wRYdVCw7/kD59cTtb9gzgfvRdld29w5w8r5nTFrexZU8QOKUD4DTmIHWjbzhLW2OCZHz6/3qlcBiv5fCzF3p4qvsA699yMi2pBB9fdzptqQTvft0iAN66upMndvQxmNFxElK5l/cFH9Ll3UoApy9u48Bwjr3HYIr09v3DrJjfwmmL2ujuHWEok6e7d4Rk3FjU3njUzz9TCgepqgMzPAAOoPWIMYdcocgPntnFFV/9Fetv+y2dbSn+8LxlALz/vGU8deNFdLalAHjbaxeQKziPvrj/GPwWUi+2hbOHVi04PBxKZ2WbadfSpl0H2dufJlco8sqBkdGWA8ALewbo2jvIsrnNxKe5cvGxVNfh4O7c/FAXD2zeE3VV6kbfcG5Gg9EA8ZjR0hBnIJ3nl137eOvnH+K6f3+SPf0Z/uo9r+OnH3376HTX0vYl5508l6ZknJ9r3GHW2NufZug4twRf3j/EnKbkmDGy08MP8pkMSu/pT/OHt/yK67/7LLsOjFAoOivmN3PaouA5b36oi59u3sM7T1t49L/AUZje2VZmmS/ct4VbHn6RpmScH33krYcNOsnxMdOlM0ram5L0j+T4zA83k4gbX7tqDe88feGU37BSiThrXzOPn+t4hxOSu3PbL7dx7ooOzlkxlz39aS7+8iNccMoCbv7gucftdbfvHxr3c6GjuYHF7Y0zCocv/3Qr6VyRh7fs5dLXLwHg5HnNrJjXTGMyxk837+XcFR18/JLTjrr+R6NuWw63/2obtzz8IpedfRLJuPHRu54iP41lGWRm+oazMzrGoaStMcGvX9rP87v7+dO3n8K7z1hUcdP7ba/t5KV9Q3SHg31y4rj32Vf59A+e56rbfsvWPQPc8N1nOTCc475Nrx7XpVG27Rtm1fzxB4VPW9zG5mmGQ9feQe7a2M2Fpy+k6PAvD24F4OT5LcRixhlL2ulsS3HLh84jlYhm2YySugyHVw6M8Hc/fJ4LT1/IF//obD59+Vk8seMAt/78pairNqv1p3P0DGSOMhyS7OwbobkhzuVnnzStx751dSeAWg8nmIMjOf72nk2cvriNVCLOH3zlVzz4u7388dqTyRed7z6x87i8bjpXYNfBkQl7FE5f0saLewcrXuvrwHCWT96zicZEjM+//w2sOXku2/YPk0rEWBiOjf3z/zyXu6+9INKB6JK6DId/eXArhvHpy88iHjPe98aTWHfmYm56YOvo0gty7N38UBeZfJHLz1464+doDwel3/fGkw4bX6jEKZ0tLO1o4pEXenhyRx8f+tpvuO0XLzOc1QymWvb5H/+O/YMZ/v79b+Rr69eQKxZZ+5p5fPJ9Z7Lm5Ll8+7HuYzKl9Eg7eodxHzsYXXL64jayhSLffqybjdt6x50JN5jJ87MXevjkPZu44HMP8vOt+/jYRaexoDXFFWuCyRMr5jWPnjJ3aUcTJ3VEd1R0ubobc9ixf5j/3LiTD755xegfwcz46/9+Bg//414+88PN3PKh8yKu5eyzY/8w3/jFNv7gnGW8ftmcGT9PKRA+cP6KaT/WzHjr6gV8/6lXeHDLXpIx4xdd+7jpwa38+btfy4fWnkw8ZvSnczzTfZDNu/t506p5nL28Y9LnHckWSMRt3Om57s4rB0boG8oxr7UhmMYbi1Fw58BwlpgZS+Y0YmZk8gUOjuTobE1hNn5XWbHoPPryfh59qZfLzj6JUzpbx92uP51j/2CW/pEcSzoaWdhWnW+ihaKTzRdpahi/S8TdGcoWaGmIj/kd3Z1Nu/r5Rdc+XreknfNOnsun7tnEXRt3cvXvrRr9v3nwY+9gXktwDvIrz1/BX/zn0/z4uVeZ35piR+8w3b3D7BvMMJjJM5jOM5DJM5DOM5jJkckViceMmBnxmJGIGy0NCZoa4rQ0xEdXQM0Vgr8bjJ3GWnLO8rnEY8Zfff85IDjC+bXhoPKB4Rx9w1ky+aBVkYwb685awnXvPHV0VtKlr1/CjRs2cfIEzx+1mgkHM1sH/BMQB77m7p87Hq9z04NbiceM//3OUw8rX9rRxHXvPJV/+MkLbHh6FxefuajiPr9C0THAjHHf1O5O0aHoTqHoeHg9X3SGMvnRb65mwT9tzBjdJlgO6NDjfYLLgyNBl03RnbbGJG2NCVpTCbL5IrsOjtA/kh+th4d1CuoGjoeXEDejJZUglYgxkiswki0wnC2QzhcO+52K7qTD+0ZyBdK5IjGDZCJGMhZ8UCbiMRriRmMyzsbtfcRjxl+uO7pBtre9tpNEzHjDDAPmHad1cudj3ax9zTxu+eB5vLRvkC/e/wI3btjEvz26HYCunkHKv4iev2oec5qSvNQzSEMizqL2FC2pBImY8VLPEM/v7qetMcElZy2muSHBxm299A3naEkl2DeYmbJPfEFrAwtaU+GqnM7i9kbOWtpOayqBE8yD39OfpikZD7s6gvMJfOWhLq5Ys5yDI1me2H6AZMJoSyXZ059mf7jAYUlnW4pV81tY0tFIU9kS0EdQPQMmAAAJfElEQVR+4XacoUyBnsEM+wYz7BvIkIzHOOOkdjpbUxwYCT70Dg7nGM4WiBnE40bcjFzB2dOfpuDO6YvbOWNJOwPpHAdGcuDB0cYv7xuiP52npSHO8nnNpJJxYhYE7L7BLPsGD+2rRMzIF53r3nkqf/77rx0tL/9mfenrF/PJDZv48LeeGC0zg7nNDaPvgdZUgqUdTbQ1tpFKxCgUnYI7xaKTKzjD2TzD4euncwXMIGbGnKYk7z9vGa9b0j7u323lghYe+8S72X1whD39aZ7qPsjT3QdIxo2zls5hXksDHc1JzjxpDm9aOZfmhsM/btsak9zyofNYVKXgni47Hs2xaVfCLA68APw+sBN4DPiAuz8/0WPWrFnjGzdunNbr9KdzXPDZB/mjNy3nr997xpj707kCl/7Tz3lp3xDJuLGwrZGGRIxsvkjfcHA+17gZDYkY7Y1J4jGjdygoP/z3IQwLG/0AP9El44ZRFnwGTck4zQ1xmpJxUsk47k6uUCRXcPKFItmCk80XSOeLZPNFbrjkdP707adE90sQhOKvX9zPm1bNG/2m7+788NndfPVnL9LZmuKcFXM5Z0UHpy5s5YfP7ObfHt1OIh7jlM4WCkVnT3+GoWyeXKHISXOaWLNyLq/0jfCT5/eQLzpnL+9gyZxGhjJ52huTnLOig4XtjfQNZRlI58kXnXgMOpoaSOcLPLPzID0DGc44qZ35LQ08s/MgW14dIJ0vUHRnxbxmlsxpIp0rUCg6F525iDetnMc/P9DFXY93s6S9kfNXzQOCAwQXtac4eX4LC9tStDUm6e4dZtOufrp7h9ndP0Imd6iP3A77kwY3mhviLGhL0dmaYkFrA8PZAs/v7ufAcI65LUnmNjcwpylJc0M8+NISftjGzVg8p5FEPMYT2/vYuneAjqbgAzJmwbf0lfNbOKmjiT39aXb2jZAtFHF3mpJxWhsTrF01n7ef1slT3Qf42Qs9XHTGIt4xxZTOX724j5d6hlgxr5nl85o5qaMx8sHcWmVmj7v7moq2rZFweAvwt+5+cXj7BgB3/+xEj5lJOADsG8yQiNmEa/scGM7yy679PPvKQfYOpMkVnETMmNfSEL4ZnHSuyEA6R77gzGtpGO3qKLoTfNEvfUMP3jAWNmFjYcuidD1mRmsqQXMqgXGoJVAoOrFYcH+4P8LnYfQ5Yha8lWOx4E3d1phgYVsj8bgxkM4xkM4zkM6RiMVYOreJjqbgDRoEV5Be5SFWavkUisE3x0y+QFMyTlP44Z+YwRHN5YpFH+1Xna0yYeuqmh9MI9kCjcnYhN1QIuWmEw610q20FOguu70TePPxeKEFralJ7+9obuA9b1jCe96w5Hi8fJUc3YDWdAd6KzHbgwGqGwolE/XtixytWpmtNN4nx5gmjZldY2YbzWxjT4+OdBUROV5qJRx2AsvLbi8Ddh25kbvf6u5r3H1NZ2dn1SonIlJvaiUcHgNWm9kqM2sArgQ2RFwnEZG6VRNjDu6eN7PrgPsIprLe5u6bIq6WiEjdqolwAHD3e4F7o66HiIjUTreSiIjUEIWDiIiMoXAQEZExauII6Zkwsx5g+wwfvgCo9XWbVcejV+v1A9XxWFEdK3Oyu1d0HMAJGw5Hw8w2VnoIeVRUx6NX6/UD1fFYUR2PPXUriYjIGAoHEREZo17D4daoK1AB1fHo1Xr9QHU8VlTHY6wuxxxERGRy9dpyEBGRSdRVOJjZOjPbYmZdZnZ91PUBMLPlZvaQmW02s01m9pGwfJ6Z3W9mW8PLuTVQ17iZPWlmPwhvrzKz34R1/Ha4aGKU9esws++Y2e/C/fmWWtuPZvbn4d/5OTP7DzNrjHo/mtltZrbXzJ4rKxt3v1ngpvA99IyZnRthHf8+/Fs/Y2bfM7OOsvtuCOu4xcwujqJ+Zff9hZm5mS0Ib0eyD6erbsIhPBXpzcAlwBnAB8xs7LlCqy8PfMzdXwesBa4N63U98IC7rwYeCG9H7SPA5rLbnwe+FNaxD7g6klod8k/Aj939dOCNBHWtmf1oZkuB/wOscfezCBaZvJLo9+M3gXVHlE203y4BVoc/1wC3RFjH+4Gz3P0NBKcZvgEgfP9cCZwZPuYr4fu/2vXDzJYTnP54R1lxVPtwWuomHIDzgS53f8nds8CdwGUR1wl33+3uT4TXBwg+0JYS1O32cLPbgcujqWHAzJYB7wG+Ft424F3Ad8JNIq2jmbUDbwO+DuDuWXc/QI3tR4LFLpvMLAE0A7uJeD+6+yNA7xHFE+23y4A7PPAo0GFmx/20iePV0d1/4u758OajBOeBKdXxTnfPuPvLQBfB+7+q9Qt9CfhLDj95WST7cLrqKRzGOxXp0ojqMi4zWwmcA/wGWOTuuyEIEGDys6wff18m+CcvnZ1+PnCg7M0Z9f58DdADfCPs+vqambVQQ/vR3V8B/oHgW+Ru4CDwOLW1H0sm2m+1+j76X8CPwus1UUczex/wirs/fcRdNVG/qdRTOFR0KtKomFkr8F/An7l7f9T1KWdm7wX2uvvj5cXjbBrl/kwA5wK3uPs5wBC10RU3Kuy3vwxYBZwEtBB0MRypZv4vx1Frf3fM7BME3bPfKhWNs1lV62hmzcAngL8Z7+5xymrub15P4VDRqUijYGZJgmD4lrt/NyzeU2pqhpd7o6ofcAHwPjPbRtAd9y6ClkRH2D0C0e/PncBOd/9NePs7BGFRS/vx3cDL7t7j7jngu8B/o7b2Y8lE+62m3kdmth54L/BBPzQvvxbqeArBl4Cnw/fNMuAJM1tcI/WbUj2FQ02eijTsu/86sNndv1h21wZgfXh9PXB3tetW4u43uPsyd19JsN8edPcPAg8B7w83i7qOrwLdZnZaWHQh8Dw1tB8JupPWmllz+Hcv1bFm9mOZifbbBuCqcMbNWuBgqfup2sxsHfBx4H3uPlx21wbgSjNLmdkqgoHf31azbu7+rLsvdPeV4ftmJ3Bu+H9aM/twUu5eNz/ApQSzGl4EPhF1fcI6/R5Bk/IZ4Knw51KCPv0HgK3h5byo6xrW9x3AD8LrryF403UB/wmkIq7b2cDGcF9+H5hba/sR+CTwO+A54F+BVNT7EfgPgjGQHMGH2NUT7TeCLpGbw/fQswQzr6KqYxdB333pffPVsu0/EdZxC3BJFPU74v5twIIo9+F0f3SEtIiIjFFP3UoiIlIhhYOIiIyhcBARkTEUDiIiMobCQURExlA4iIjIGAoHEREZQ+EgIiJj/H90OG4gnxuKwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
